{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook is for tagging videos based from their JSON files as returned when sent through the Amazon Rekognition\n",
    "#Image Processing API\n",
    "\n",
    "#Please refer to the README before attempting to run or alter the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.- INITIALISATION KERNEL:\n",
    "\n",
    "#Import for visualization\n",
    "%matplotlib inline \n",
    "\n",
    "#Essential imports\n",
    "import pandas as pd\n",
    "import sys \n",
    "import os\n",
    "import platform\n",
    "from pathlib import *\n",
    "import json \n",
    "import random\n",
    "from datetime import datetime\n",
    "import ntpath\n",
    "import numpy as np\n",
    "\n",
    "#--------------------------FUNCTIONS----------------------------------------------------------------\n",
    "#kernel holding a function to convert json date into a date/time object\n",
    "\n",
    "def ConvertToDate(strDate):\n",
    "    convDate = datetime.strptime(strDate,'%a, %d %b %Y %H:%M:%S %Z')\n",
    "    return convDate\n",
    "\n",
    "\n",
    "#kernel that will hold the function that chooses tags from labels (atm randomly)\n",
    "\n",
    "#Function that will tag videos\n",
    "\n",
    "def GetVideoTag(labels, freqdict):\n",
    "#  labels is list of lists of joint labels\n",
    "#  Select least common labels considering their frequency from equal confidence levels\n",
    "\n",
    "    tag = \"\" #tag that will be returned_lbl\n",
    "    for poss_lbl in labels: # loop through lists of lists\n",
    "        freq = 1000000 #arbitrary high number of frequencies as initial value\n",
    "        chosen_lbl = \"\" # looping variable\n",
    "        for lbl in poss_lbl:\n",
    "            if lbl in freqdict:\n",
    "                #choose label with the least frequencies by finding its freq from the dictionary\n",
    "                if(freqdict[lbl] < freq):\n",
    "                    freq = freqdict[lbl]\n",
    "                    chosen_lbl = lbl\n",
    "        tag = chosen_lbl+\" \"+tag # append tag\n",
    "    return tag\n",
    "\n",
    "\n",
    "#Function to get directory\n",
    "\n",
    "def GetValidDirectoryPath():\n",
    "    #Boolean control to get valid path\n",
    "    valid_path_given = False\n",
    "    path = \"\"\n",
    "    \n",
    "    #loop until a valid path is given\n",
    "    while valid_path_given == False:\n",
    "        attempted_path = input(\"Please enter the path of your directory containing videos (with forward slashes):\")\n",
    "        #Check if directory exists, if it does exit loop, or loop until a valid directory is found\n",
    "        if os.path.isdir(attempted_path) == False:\n",
    "            print(\"Invalid directory path, please try again.\") # If it doesn't exist send error message\n",
    "               \n",
    "        else:\n",
    "            print(\"Successful Path entered.\")\n",
    "            path = attempted_path\n",
    "            valid_path_given = True\n",
    "    return path\n",
    "\n",
    "#Label processing functions \n",
    "\n",
    "#Get label list and sort it in a dictionary keyed by frequency\n",
    "def wordListToFreqDict(wordlist):\n",
    "    wordfreq = [wordlist.count(p) for p in wordlist]\n",
    "    return dict(zip(wordlist,wordfreq))\n",
    "\n",
    "#Make a function which makes a list sorted by higher frequency labels for visual purposes\n",
    "def sortFreqDict(freqdict): \n",
    "    aux = [(freqdict[key], key) for key in freqdict]\n",
    "    aux.sort()\n",
    "    aux.reverse()\n",
    "    return aux\n",
    "\n",
    "\n",
    "#-------------------------ESSENTIAL VARIABLES-------------------------------------------------------\n",
    "\n",
    "#Main data frame columns and lists\n",
    "list_labels = ['Date' , 'Description', 'FileName', 'RequestID']\n",
    "date_list = []\n",
    "tag_list =[] \n",
    "filename_list = []\n",
    "requestID_list = []\n",
    "file_errors = []\n",
    "\n",
    "#check what system program is being run for file output\n",
    "current_platform = platform.system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.- CUSTOMISATION KERNEL\n",
    "#------------------------CUSTOMISABLE VARIABLES--------------------------------------------------------\n",
    "\n",
    "#LABEL SETTINGS:\n",
    "#====================================================================================================\n",
    "#Set a limit of confidence percentage to filter labels\n",
    "confidence_threshold = 75.0 #75% confidence and up\n",
    "conf_decimal_points = 5 #aws default is 14, making confidences less accurate may increase tagging performance\n",
    "\n",
    "\n",
    "#INPUT AND OUTPUT SETTINGS:\n",
    "#=====================================================================================================\n",
    "#Get directory path containing video descriptions\n",
    "\n",
    "#Will prompt user until a valid path is given, comment out and assign variable directly if known\n",
    "directory_path = GetValidDirectoryPath()\n",
    "\n",
    "#directory_path = \"YOUR PATH HERE\" (Forward slahes preferable)\n",
    "\n",
    "#Output path, please use forward slashes\n",
    "output_file_name = directory_path+'/final_tags.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.- LABEL PROCESSING KERNEL\n",
    "\n",
    "#Kernel for obtaining label frequency dictionary from dataset\n",
    "\n",
    "#Set directory for parsing\n",
    "label_dir = os.fsencode(directory_path)\n",
    "\n",
    "#String that is going to hold all labels\n",
    "total_labels = \"\"\n",
    "\n",
    "#Go through each file in directory\n",
    "for enc_file in os.listdir(label_dir):\n",
    "    #got to decode file first\n",
    "    curr_file = os.fsdecode(enc_file)\n",
    "    \n",
    "    #check for valid extensions\n",
    "    if curr_file.endswith(\".res\") or curr_file.endswith(\".json\"): \n",
    "        file_path= directory_path+\"/\"+curr_file\n",
    "        with open(file_path) as j:\n",
    "            first_data = json.load(j)\n",
    "            \n",
    "             #obtain label portion of json\n",
    "            data_lab = first_data['Labels'][:]\n",
    "            conf_values = set()\n",
    "    \n",
    "            #Loop through labels to get confidence values\n",
    "            #List of dictionaries so nested for loop needed to filter values\n",
    "            \n",
    "            for indiv_labels in data_lab:\n",
    "                for key,value in indiv_labels.items():\n",
    "                    #append filtered values into a set\n",
    "                    if key == 'Name':\n",
    "                        #Add '-' as delimeter for two-word labels e.g. \"Airport Terminal\" to be properly processed\n",
    "                        total_labels +=(\"-\"+value)\n",
    "\n",
    "#make a list of all labels getting split by delimiter                    \n",
    "listed_strs = total_labels.split(\"-\")\n",
    "\n",
    "#Make a dictionary of labels keyed by frequency\n",
    "my_dict = wordListToFreqDict(listed_strs)\n",
    "\n",
    "#get a sorted list for visualisation of most frequent labels in descending order\n",
    "sorted_labels = sortFreqDict(my_dict)\n",
    "\n",
    "#print sorted list\n",
    "print(sorted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.- MAIN KERNEL\n",
    "\n",
    "#Set directory for parsing\n",
    "directory = os.fsencode(directory_path)\n",
    "\n",
    "#Go through each file in directory\n",
    "for encoded_file in os.listdir(directory):\n",
    "    \n",
    "    #got to decode file first\n",
    "    current_file = os.fsdecode(encoded_file)\n",
    "    \n",
    "    #check for valid extensions\n",
    "    if current_file.endswith(\".res\") or current_file.endswith(\".json\"): \n",
    "        str_file_path= directory_path+\"/\"+current_file\n",
    "        with open(str_file_path) as f:\n",
    "            data = json.load(f)\n",
    "    \n",
    "            #getting filename to append\n",
    "            name_ = os.path.basename(current_file)\n",
    "    \n",
    "            #obtain date portion of json \n",
    "            video_date = (data['ResponseMetadata']['HTTPHeaders'])['date']\n",
    "            #convert date string into datetime object\n",
    "            date = ConvertToDate(video_date)\n",
    "    \n",
    "            #obtain request id of json\n",
    "            request_id = (data['ResponseMetadata']['HTTPHeaders'])['x-amzn-requestid']\n",
    "    \n",
    "            #obtain label portion of json\n",
    "            data_labels = data['Labels'][:]\n",
    "            confidence_values = set()\n",
    "    \n",
    "            #Loop through labels to get confidence values\n",
    "            #List of dictionaries so nested for loop needed to filter values\n",
    "            for individual_labels in data_labels:\n",
    "                for key,value in individual_labels.items():\n",
    "                    #append filtered values into a set\n",
    "                    if key == 'Confidence' and value >= confidence_threshold:\n",
    "                        #round to control confidence similarity\n",
    "                        rounded_value = round(value, conf_decimal_points)\n",
    "                        confidence_values.add(rounded_value) \n",
    "                \n",
    "    \n",
    "            #Cluster labels of equal confidence into a list\n",
    "            label_groups = []\n",
    "            #Loop through labels section of json file again\n",
    "            for different_values in confidence_values:\n",
    "                equal_labels = [] #cluster labels of same confidence\n",
    "                for labels in data_labels:\n",
    "                    for key, value in labels.items():\n",
    "                        if key == 'Confidence':\n",
    "                            rounded_value = round(value, conf_decimal_points)\n",
    "                            if rounded_value == different_values:\n",
    "                                equal_labels.append(labels['Name'])\n",
    "                        \n",
    "                label_groups.append(equal_labels) #make a list of lists of labels\n",
    "                    \n",
    "            generated_tag = GetVideoTag(label_groups, my_dict) # get a generated tag\n",
    "            \n",
    "            #check to see if there are any labels\n",
    "            if not generated_tag:\n",
    "                generated_tag = \"---NO LABELS DETECTED---\"\n",
    "            \n",
    "            #Add particular json data into lists\n",
    "            \n",
    "            date_list.append(date)\n",
    "            tag_list.append(generated_tag)\n",
    "            filename_list.append(name_)\n",
    "            requestID_list.append(request_id)   \n",
    "            \n",
    "        \n",
    "    else:\n",
    "        #make error log\n",
    "        name = os.path.basename(current_file)\n",
    "        file_errors.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#5.- DATA PROCESSING AND SUBMISSION KERNEL\n",
    "\n",
    "#Kernel that wraps up entire info into a data frame\n",
    "\n",
    "#convert to nparrays for sorting\n",
    "dates = np.array(date_list)\n",
    "tags = np.array(tag_list)\n",
    "filenames = np.array(filename_list)\n",
    "IDS = np.array(requestID_list)\n",
    "\n",
    "#Sort dates which is main parameter by indexes\n",
    "inds = dates.argsort()\n",
    "\n",
    "#flip dates because its more convenient in descending order\n",
    "inds = np.flip(inds, axis=0)   \n",
    "\n",
    "#Assign sorted indexes\n",
    "dates = dates[inds]\n",
    "tags = tags[inds]\n",
    "filenames = filenames[inds]\n",
    "IDS = IDS[inds]\n",
    "\n",
    "\n",
    "#Convert back to lists for processing\n",
    "date_list = np.ndarray.tolist(dates)\n",
    "tag_list = np.ndarray.tolist(tags)\n",
    "filename_list = np.ndarray.tolist(filenames)\n",
    "requestID_list = np.ndarray.tolist(IDS)\n",
    "\n",
    "#Conjoin tags for placing info on a dataframe\n",
    "gen_list = [date_list, tag_list, filename_list, requestID_list]\n",
    "zipped = list(zip(list_labels, gen_list))\n",
    "df_data = dict(zipped)\n",
    "final_df = pd.DataFrame(df_data)\n",
    "final_df.set_index('Date')\n",
    "\n",
    "#Output error files inside directory\n",
    "print(\"FILES UNABLE TO BE PROCESSED DUE TO ERROR OR BECAUSE NOT IN JSON FORMAT: \")\n",
    "print(file_errors)\n",
    "\n",
    "#Output sorted dataframe into a csv file into the selected path\n",
    "final_df.to_csv(output_file_name, index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
